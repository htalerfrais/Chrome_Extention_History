---
alwaysApply: true
---
# Current Architecture - Chrome Extension History Project

> **⚠️ IMPORTANT**: This document must be updated whenever the architecture is modified, components are added/removed, or significant structural changes are made to the project.

## Overview

This is a **Chrome Extension + React Frontend + Backend API** system that analyzes browsing history and organizes it into thematic sessions using AI-powered LLM services. The architecture follows a modern client-server pattern with React UI, extension services bridge, and remote AI analysis capabilities.

## High-Level Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                    CHROME EXTENSION (Frontend)                  │
├─────────────────────────────────────────────────────────────────┤
│  Background Service Worker  │  Popup Interface  │  React Dashboard│
│  - Data Collection          │  - Quick Search   │  - Modern UI    │
│  - Real-time Updates       │  - History Lookup │  - State Mgmt   │
│  - Local Storage           │  - Simple UI      │  - Component Tree│
│                             │                   │  - ExtensionBridge│
└─────────────────────────────────────────────────────────────────┘
                                │
                                │ ExtensionBridge Pattern
                                │ (React ↔ Extension Services)
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                    EXTENSION SERVICES LAYER                     │
├─────────────────────────────────────────────────────────────────┤
│  Session Management  │  API Client       │  Data Processing    │
│  - session_mgmt.js   │  - api_client.js  │  - preprocess.js   │
│  - Time grouping     │  - HTTP comm      │  - URL filtering   │
│  - API formatting    │  - Error handling │  - Feature extract │
└─────────────────────────────────────────────────────────────────┘
                                │
                                │ HTTP API Calls
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                    BACKEND API (Python FastAPI)                 │
├─────────────────────────────────────────────────────────────────┤
│  FastAPI Server  │  Clustering Service  │  LLM Service         │
│  - REST Endpoints│  - Theme Detection   │  - AI Text Generation│
│  - Health Checks │  - Pattern Analysis  │  - Multi-Provider   │
│  - CORS Support  │  - Keyword Matching  │  - Provider Abstraction│
│                  │  - Session Clustering│  - OpenAI/Anthropic │
│                  │                      │  - Google/Ollama    │
└─────────────────────────────────────────────────────────────────┘
                                │
                                │ Data Models & Validation
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                    DATA LAYER (Pydantic Models)                  │
├─────────────────────────────────────────────────────────────────┤
│  Session Models  │  LLM Models         │  Validation           │
│  - HistoryItem   │  - LLMRequest       │  - Type Safety        │
│  - HistorySession│  - LLMResponse      │  - Input Validation   │
│  - ClusterResult │  - Provider Support │  - Error Handling    │
│  - ClusteringResp│  - Multi-Provider   │  - Schema Validation  │
└─────────────────────────────────────────────────────────────────┘
```

## Component Responsibilities

### **Frontend (Chrome Extension + React)**

#### **Background Service Worker** (`background.js`)
- **Responsibility**: Continuous data collection and preprocessing
- **Key Functions**:
  - Collects Chrome history data (up to 5000 items)
  - Real-time updates via `chrome.history.onVisited` listener
  - Stores preprocessed data in `chrome.storage.local`
  - Applies URL filtering and deduplication

#### **Popup Interface** (`popup.html`, `popup.js`)
- **Responsibility**: Quick access search interface
- **Key Functions**:
  - Simple search functionality across stored history
  - Displays search results with favicons and metadata
  - Provides access to React dashboard
  - Compact 320px width design

#### **React Dashboard** (`frontend/src/`)
- **Responsibility**: Modern UI with lazy loading and on-demand session analysis
- **Key Functions**:
  - **App Component**: Main state management with lazy loading architecture
  - **Session State Management**: Tracks analysis states (pending/loading/completed/error) per session
  - **Header Component**: Logo, title, and action buttons with click handlers
  - **StatusBar Component**: Real-time status updates with loading/success/error states
  - **Dashboard Component**: Main content area for session and cluster display
  - **SessionTabs Component**: Interactive session navigation with analysis state indicators
  - **LoadingSpinner & ErrorDisplay**: User feedback components
  - **ExtensionBridge Service**: Clean interface to extension services

#### **Extension Services Bridge** (`frontend/src/services/extensionBridge.ts`)
- **Responsibility**: Connect React UI to existing extension services
- **Key Functions**:
  - Access Chrome storage and APIs
  - Use existing SessionManager for data processing
  - `clusterSession()` method for single session backend communication
  - Provide type-safe interface for React components
  - Handle service initialization and error recovery

#### **Data Processing Layer** (`extension/utils/`)
- **Session Manager** (`session_management.js`):
  - Groups history items into time-based sessions (120min gap)
  - Formats data for API consumption
  - Handles session statistics and validation
- **History Preprocessor** (`preprocess_history.js`):
  - URL normalization and cleaning
  - Duplicate detection and removal
  - Feature extraction (hostname, path, search queries)
  - Date formatting and enrichment

#### **API Client** (`extension/api/`)
- **API Client** (`api_client.js`):
  - Handles HTTP communication with backend
  - `clusterSession()` method for single session processing
  - Implements retry logic and error handling
  - Manages request timeouts and failures
- **Configuration** (`config.js`):
  - Environment management (dev/production)
  - API endpoint configuration
  - Request settings and timeouts

### **Backend (Python FastAPI)**

#### **API Server** (`main.py`)
- **Responsibility**: RESTful API endpoints and request handling
- **Key Functions**:
  - Health check endpoints (`/`, `/health`)
  - Single session clustering endpoint (`/cluster-session`)
  - LLM text generation endpoint (`/llm/generate`)
  - CORS configuration for Chrome extension
  - Error handling and logging

#### **Clustering Service** (`clustering_service.py`)
- **Responsibility**: LLM-driven thematic clustering for single session analysis
- **Key Functions**:
  - **Single session processing**: `cluster_session()` method processes one session at a time
  - **LLM-powered cluster identification**: Uses AI to propose thematic clusters per session
  - **Intelligent item assignment**: Batched LLM calls to assign items to identified clusters
  - **On-demand analysis**: Enables lazy loading and faster initial response times
  - **Robust error handling**: Fallback mechanisms for LLM failures
  - **JSON extraction**: Parses LLM responses with error recovery
  - **Batch optimization**: Groups items for efficient LLM API usage

#### **LLM Service** (`llm_service.py`)
- **Responsibility**: AI-powered text generation and analysis
- **Key Functions**:
  - Multi-provider LLM abstraction
  - Provider management and routing
  - Request validation and error handling
  - Usage tracking and metadata extraction

#### **LLM Providers** (`providers/`)
- **Provider Interface** (`base_provider.py`):
  - Abstract base class for all LLM providers
  - Standardized interface for text generation
  - Request validation and model management
- **OpenAI Provider** (`openai_provider.py`):
  - GPT models integration (GPT-3.5, GPT-4)
  - OpenAI API communication
  - Token usage tracking
- **Anthropic Provider** (`anthropic_provider.py`):
  - Claude models integration (Claude-3 Sonnet)
  - Anthropic API communication
  - Usage metadata extraction
- **Google Provider** (`google_provider.py`):
  - Gemini models integration (Gemini-1.5 Flash/Pro)
  - Google Generative AI API
  - Response parsing and metadata
- **Ollama Provider** (`ollama_provider.py`):
  - Local LLM models (Llama2, etc.)
  - Local API communication
  - Offline text generation capability

#### **Data Models** (`models/`)
- **Session Models** (`session_models.py`):
  - `HistoryItem`: Individual browsing entry
  - `HistorySession`: Time-grouped browsing session
  - `ClusterResult`: Thematic grouping result
  - `SessionClusteringResponse`: API response format
- **LLM Models** (`llm_models.py`):
  - `LLMRequest`: Text generation request with provider settings
  - `LLMResponse`: Generated text with metadata and usage info
  - Provider-agnostic request/response handling

## React Frontend Architecture

### **Component Tree**
```
App (State Management + ExtensionBridge)
├── Header (Logo + Action Buttons)
├── StatusBar (Loading/Success/Error States)
├── LoadingSpinner (Conditional Rendering)
├── ErrorDisplay (Error Handling + Retry)
└── Dashboard (Main Content)
    ├── SessionTabs (Session Navigation)
    └── ClustersSection (Cluster Display)
        ├── SessionInfo (Session Metadata)
        └── ClusterGrid
            └── ClusterCard[] (Individual Clusters)
                └── ClusterItem[] (History Items)
```

### **State Management**
- **React Hooks**: useState, useEffect for local component state
- **Lazy Loading State**: `availableSessions`, `sessionAnalysisStates` for on-demand processing
- **Props Flow**: Top-down data flow with callback props for user actions
- **ExtensionBridge**: Service layer for Chrome extension integration
- **Type Safety**: TypeScript interfaces for all props and state

### **Build Process**
- **Development**: Vite dev server at `http://localhost:5173`
- **Production**: Vite builds to `extension/dashboard-assets/`
- **Chrome Extension**: Loads React bundle from `dashboard-assets/index.js`
- **CSS**: Bundled into `dashboard-assets/assets/index.css`

## LLM Clustering Workflow

The clustering service now operates through a sophisticated two-phase LLM-driven process:

### **Phase 1: Cluster Identification**
1. **Session Analysis**: Each session is processed independently
2. **LLM Prompting**: Simplified item data (title, hostname, path, search query) sent to LLM
3. **Cluster Proposal**: LLM returns 3-8 thematic clusters with IDs, themes, and summaries
4. **Schema Validation**: Response parsed and cleaned with fallback to generic cluster

### **Phase 2: Item Assignment**
1. **Batch Processing**: Items grouped into batches of 20 for efficiency
2. **LLM Assignment**: Each batch assigned to identified clusters via LLM
3. **Error Recovery**: Fallback mechanisms ensure all items are assigned
4. **Result Assembly**: ClusterResult objects created with assigned items

### **Key Features**
- **Provider Flexibility**: Uses Google Gemini by default, configurable to other providers
- **Robust Parsing**: JSON extraction with error recovery from malformed LLM responses
- **Performance Optimization**: Batched processing reduces API calls and costs
- **Graceful Degradation**: Fallback clusters ensure system reliability

## Data Flow

### **Initial Load (Fast)**
1. **Data Collection**: Chrome history → Background worker → Local storage
2. **React Initialization**: Dashboard loads → ExtensionBridge waits for services
3. **User Action**: Click Refresh → React loads session list only
4. **Service Layer**: ExtensionBridge → SessionManager → Local processing
5. **UI Update**: Session tabs display with "Click to analyze" status

### **On-Demand Analysis (Per Session)**
1. **User Action**: Click session tab → Triggers `analyzeSession(sessionId)`
2. **Service Layer**: ExtensionBridge → ApiClient → Backend `/cluster-session`
3. **LLM Processing**: Backend receives single session → LLM cluster identification → Batched item assignment
4. **AI Enhancement**: LLM service generates thematic clusters and assigns items intelligently
5. **React Update**: Backend returns single session result → React state updates → UI re-renders

## Key Design Patterns

- **Extension Services Bridge Pattern**: Clean separation between React UI and Chrome extension services
- **Service Worker Pattern**: Background processing for continuous data collection
- **API Gateway Pattern**: Centralized backend service for complex processing
- **Provider Abstraction Pattern**: Unified interface for multiple LLM providers
- **Lazy Loading Pattern**: On-demand session analysis for improved performance
- **Session-based Processing**: Groups related browsing activities by time
- **LLM-driven Clustering**: AI-powered thematic analysis and intelligent categorization
- **Component Composition**: React components with clear responsibilities
- **Props Down, Events Up**: Unidirectional data flow with callback props
- **Batch Processing Pattern**: Efficient LLM API usage through item batching
- **Fallback Strategy Pattern**: Robust error handling with graceful degradation
- **Separation of Concerns**: Extension handles data/APIs, React handles UI/UX
- **Single Responsibility Principle**: Each session analyzed independently

## Technology Stack

### Frontend
- **React 18**: Modern UI library with hooks and functional components
- **TypeScript**: Type safety and better developer experience
- **Vite**: Fast build tool and development server
- **Chrome Extension API**: History, Storage, Tabs permissions
- **ExtensionBridge Pattern**: Service layer for Chrome API access
- **CSS**: Component-based styling with build-time bundling

### Backend
- **FastAPI**: Modern Python web framework
- **Pydantic**: Data validation and serialization
- **httpx**: Async HTTP client for LLM API calls
- **Docker**: Containerized deployment
- **Uvicorn**: ASGI server

### LLM Integration
- **OpenAI API**: GPT models for text generation
- **Anthropic API**: Claude models for advanced reasoning
- **Google Generative AI**: Gemini models for multimodal capabilities
- **Ollama**: Local LLM models for offline processing

## Configuration

- **Session Gap**: 120 minutes between sessions
- **History Limit**: 5000 items maximum
- **API Timeout**: 30 seconds for main requests
- **Retry Logic**: 3 attempts with exponential backoff
- **LLM Clustering**: AI-powered thematic analysis with Google Gemini (primary provider)
- **Batch Size**: 20 items per LLM assignment call for efficiency
- **LLM Providers**: Configurable via environment variables
- **API Keys**: Secure environment-based configuration
- **React Build**: Outputs to extension/dashboard-assets/ for Chrome extension compatibility

## Environment Variables

- `OPENAI_API_KEY`: OpenAI API access key
- `ANTHROPIC_API_KEY`: Anthropic API access key
- `GOOGLE_API_KEY`: Google Generative AI API key
- `OLLAMA_BASE_URL`: Custom Ollama server URL (default: localhost:11434)

## Deployment

- **Extension**: Chrome Web Store (future) / Developer mode (current)
- **Backend**: Docker container on localhost:8000 (dev) / Cloud (production)
- **React Frontend**: Built into extension/dashboard-assets/ via Vite
- **Development**: Docker Compose for backend + Vite dev server for React
- **LLM Services**: External API dependencies (OpenAI, Anthropic, Google)

## Development Workflow

1. **Backend**: `.\scripts\dev_up.ps1` (Docker)
2. **Frontend**: `cd frontend && npm run dev` (Vite dev server)
3. **Extension**: Load unpacked from `extension/` folder
4. **Production**: `cd frontend && npm run build` (builds to extension/)

---

**Last Updated**: September 23, 2025
**Version**: 0.6.0
**Status**: Lazy Loading Architecture Complete ⚡